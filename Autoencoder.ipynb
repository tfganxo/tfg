{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dab46e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs\n",
    "import mglearn\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Gráficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "#style.use('ggplot') or plt.style.use('ggplot')\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Configuración warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Random global\n",
    "seed = 12345\n",
    "rng = np.random.default_rng(seed)  # can be called without a seed\n",
    "rng.random()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv (r\"C:\\Users\\White\\Desktop\\tfg\\generados\\RFECved.csv\")\n",
    "dfNon = pd.read_csv (r\"C:\\Users\\White\\Desktop\\tfg\\generados\\scaled.csv\")\n",
    "df2 = pd.read_csv (r\"C:\\Users\\White\\Desktop\\tfg\\generados\\Deoutliers2.csv\")\n",
    "dfR = pd.read_csv (r\"C:\\Users\\White\\Desktop\\tfg\\generados\\Raw-ishDf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9158c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()\n",
    "X[\"LabelA\"]=df2[\"LabelA\"]\n",
    "y = X.pop(\"LabelA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55f18e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5faf1431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Input Layer\n",
    "input_layer = Input(shape =(X.shape[1], ))\n",
    "  \n",
    "# Building the Encoder network\n",
    "encoded = Dense(100, activation ='tanh',\n",
    "                activity_regularizer = regularizers.l1(10e-5))(input_layer)\n",
    "encoded = Dense(50, activation ='tanh',\n",
    "                activity_regularizer = regularizers.l1(10e-5))(encoded)\n",
    "encoded = Dense(25, activation ='tanh',\n",
    "                activity_regularizer = regularizers.l1(10e-5))(encoded)\n",
    "encoded = Dense(12, activation ='tanh',\n",
    "                activity_regularizer = regularizers.l1(10e-5))(encoded)\n",
    "encoded = Dense(6, activation ='relu')(encoded)\n",
    "  \n",
    "# Building the Decoder network\n",
    "decoded = Dense(12, activation ='tanh')(encoded)\n",
    "decoded = Dense(25, activation ='tanh')(decoded)\n",
    "decoded = Dense(50, activation ='tanh')(decoded)\n",
    "decoded = Dense(100, activation ='tanh')(decoded)\n",
    "  \n",
    "# Building the Output Layer\n",
    "output_layer = Dense(X.shape[1], activation ='relu')(decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fee50d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = MinMaxScaler().fit_transform(X)\n",
    "X_normal_scaled = X_scaled[y == 0]\n",
    "X_fraud_scaled = X_scaled[y == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf456ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13661/13661 [==============================] - 21s 1ms/step - loss: 0.0771 - val_loss: 0.0711\n",
      "Epoch 2/10\n",
      "13661/13661 [==============================] - 21s 2ms/step - loss: 0.0587 - val_loss: 0.0668\n",
      "Epoch 3/10\n",
      "13661/13661 [==============================] - 21s 2ms/step - loss: 0.0531 - val_loss: 0.0654\n",
      "Epoch 4/10\n",
      "13661/13661 [==============================] - 20s 1ms/step - loss: 0.0510 - val_loss: 0.0627\n",
      "Epoch 5/10\n",
      "13661/13661 [==============================] - 21s 2ms/step - loss: 0.0492 - val_loss: 0.0601\n",
      "Epoch 6/10\n",
      "13661/13661 [==============================] - 21s 2ms/step - loss: 0.0473 - val_loss: 0.0513\n",
      "Epoch 7/10\n",
      "13661/13661 [==============================] - 21s 2ms/step - loss: 0.0441 - val_loss: 0.0468\n",
      "Epoch 8/10\n",
      "13661/13661 [==============================] - 20s 1ms/step - loss: 0.0428 - val_loss: 0.0432\n",
      "Epoch 9/10\n",
      "13661/13661 [==============================] - 20s 1ms/step - loss: 0.0419 - val_loss: 0.0399\n",
      "Epoch 10/10\n",
      "13661/13661 [==============================] - 21s 2ms/step - loss: 0.0413 - val_loss: 0.0374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e60014ce80>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the parameters of the Auto-encoder network\n",
    "autoencoder = Model(input_layer, output_layer)\n",
    "autoencoder.compile(optimizer =\"adadelta\", loss =\"mse\")\n",
    "  \n",
    "# Training the Auto-encoder network\n",
    "autoencoder.fit(X_normal_scaled, X_normal_scaled, \n",
    "                batch_size = 16, epochs = 10, \n",
    "                shuffle = True, validation_split = 0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17fec8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_representation = Sequential()\n",
    "hidden_representation.add(autoencoder.layers[0])\n",
    "hidden_representation.add(autoencoder.layers[1])\n",
    "hidden_representation.add(autoencoder.layers[2])\n",
    "hidden_representation.add(autoencoder.layers[3])\n",
    "hidden_representation.add(autoencoder.layers[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38600179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the points encoded by the Auto-encoder as normal and fraud\n",
    "normal_hidden_rep = hidden_representation.predict(X_normal_scaled)\n",
    "fraud_hidden_rep = hidden_representation.predict(X_fraud_scaled)\n",
    "  \n",
    "# Combining the encoded points into a single table \n",
    "encoded_X = np.append(normal_hidden_rep, fraud_hidden_rep, axis = 0)\n",
    "y_normal = np.zeros(normal_hidden_rep.shape[0])\n",
    "y_fraud = np.ones(fraud_hidden_rep.shape[0])\n",
    "encoded_y = np.append(y_normal, y_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e491e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the encoded data for linear classification\n",
    "X_train_encoded, X_test_encoded, y_train_encoded, y_test_encoded = train_test_split(encoded_X, encoded_y, test_size = 0.2)\n",
    "  \n",
    "# Splitting the original data for non-linear classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1fc6e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9957024347878171\n"
     ]
    }
   ],
   "source": [
    "# Building the logistic regression model\n",
    "lrclf = LogisticRegression()\n",
    "lrclf.fit(X_train_encoded, y_train_encoded)\n",
    "  \n",
    "# Storing the predictions of the linear model\n",
    "y_pred_lrclf = lrclf.predict(X_test_encoded)\n",
    "  \n",
    "# Evaluating the performance of the linear model\n",
    "print('Accuracy : '+str(accuracy_score(y_test_encoded, y_pred_lrclf)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "007565d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'learning_rate': 0.1, 'n_estimators': 200}\n",
      "0.9956612562789606\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'learning_rate': 0.1, 'n_estimators': 200}\n",
      "0.9958634055359697\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'learning_rate': 0.1, 'n_estimators': 200}\n",
      "0.9956275640471033\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'learning_rate': 0.1, 'n_estimators': 200}\n",
      "0.9959270479054109\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'learning_rate': 0.1, 'n_estimators': 200}\n",
      "0.995665000335198\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "X = encoded_X\n",
    "y = encoded_y\n",
    "\n",
    "dfInterno=pd.DataFrame()\n",
    "scoring = {'accuracy', \"precision\", \"recall\",  \"f1\"}\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# define the model with default hyperparameters\n",
    "model = AdaBoostClassifier()\n",
    "# define the grid of values to search\n",
    "p_grid = dict()\n",
    "p_grid['n_estimators'] = [100,200]\n",
    "p_grid['learning_rate'] = [0.1,0.001,0.0001]\n",
    "\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# Nested CV with parameter optimization\n",
    "for train_index, test_index in outer_cv.split(X,y):\n",
    "    X_train,X_test= X[train_index,:], X[test_index,:] \n",
    "    y_train,y_test= y[train_index], y[test_index]\n",
    "        \n",
    "    grid = GridSearchCV(model,return_train_score=True,scoring=scoring, refit=\"accuracy\",param_grid=p_grid, n_jobs=-1, cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=1), verbose=4)\n",
    "    pipe= make_pipeline(MinMaxScaler(),StandardScaler(),grid)\n",
    "    fittedgrid=pipe.fit(X_train, y_train)\n",
    "#Saving the 25 subresults\n",
    "    dfCurrent= pd.DataFrame(grid.cv_results_)\n",
    "    dfInterno = pd.concat([dfInterno, dfCurrent], axis=0)\n",
    "#Saving the best params and the results\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)\n",
    "    #dfBest= pd.concat([dfBest, dfCurrentBest], axis=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "995eb369",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInterno.to_csv(r\"C:\\Users\\White\\Desktop\\tfg\\generados\\AdaboostEncodedGridSearchCVAtaques.csv\", index = None, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39873b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "{'alpha': 1e-05, 'max_iter': 100}\n",
      "0.9991052985774138\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "{'alpha': 0.001, 'max_iter': 100}\n",
      "0.9991726822002877\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "{'alpha': 1e-05, 'max_iter': 100}\n",
      "0.9991689381440505\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "{'alpha': 1e-05, 'max_iter': 100}\n",
      "0.9991502209459495\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "{'alpha': 1e-05, 'max_iter': 100}\n",
      "0.9991389896180796\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X = encoded_X\n",
    "y = encoded_y\n",
    "\n",
    "dfInterno=pd.DataFrame()\n",
    "scoring = {'accuracy', \"precision\", \"recall\",  \"f1\"}\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# define the model with default hyperparameters\n",
    "model = clf = MLPClassifier(alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "# define the grid of values to search\n",
    "p_grid = dict()\n",
    "p_grid['alpha'] = [1e-5, 1e-3]\n",
    "p_grid['max_iter'] = [100,200]\n",
    "\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# Nested CV with parameter optimization\n",
    "for train_index, test_index in outer_cv.split(X,y):\n",
    "    X_train,X_test= X[train_index,:], X[test_index,:] \n",
    "    y_train,y_test= y[train_index], y[test_index]\n",
    "        \n",
    "    grid = GridSearchCV(model,return_train_score=True,scoring=scoring, refit=\"accuracy\",param_grid=p_grid, n_jobs=-1, cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=1), verbose=4)\n",
    "    pipe= make_pipeline(MinMaxScaler(),StandardScaler(),grid)\n",
    "    fittedgrid=pipe.fit(X_train, y_train)\n",
    "#Saving the 25 subresults\n",
    "    dfCurrent= pd.DataFrame(grid.cv_results_)\n",
    "    dfInterno = pd.concat([dfInterno, dfCurrent], axis=0)\n",
    "#Saving the best params and the results\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)\n",
    "    #dfBest= pd.concat([dfBest, dfCurrentBest], axis=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9879223",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInterno.to_csv(r\"C:\\Users\\White\\Desktop\\tfg\\generados\\MLPEncodedGridSearchCV.csv\", index = None, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "104f5eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'max_depth': 5, 'n_estimators': 100}\n",
      "0.997708962708179\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'max_depth': 5, 'n_estimators': 100}\n",
      "0.9977351682990345\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'max_depth': 5, 'n_estimators': 100}\n",
      "0.9976827582384452\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'max_depth': 5, 'n_estimators': 200}\n",
      "0.9976490681086908\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'max_depth': 5, 'n_estimators': 200}\n",
      "0.9976865032055937\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "X = encoded_X\n",
    "y = encoded_y\n",
    "\n",
    "dfInterno=pd.DataFrame()\n",
    "# define the model with default hyperparameters\n",
    "model=RandomForestClassifier(random_state=42)\n",
    "scoring = {'accuracy', \"precision\", \"recall\",  \"f1\"}\n",
    "\n",
    "# define the grid of values to search\n",
    "p_grid = { \n",
    "    'n_estimators': [100, 200],\n",
    "    #Empirical good default values [...] max_features=sqrt(n_features) for classification tasks\n",
    "   # 'max_features': [\"auto\", \"sqrt\"],\n",
    "    'max_depth' : [3,4,5],\n",
    "    #'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# Nested CV with parameter optimization\n",
    "for train_index, test_index in outer_cv.split(X,y):\n",
    "    X_train,X_test= X[train_index,:], X[test_index,:] \n",
    "    y_train,y_test= y[train_index], y[test_index]\n",
    "        \n",
    "    grid = GridSearchCV(model,return_train_score=True,scoring=scoring, refit=\"accuracy\",param_grid=p_grid, n_jobs=-1, cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=1), verbose=4)\n",
    "    pipe= make_pipeline(MinMaxScaler(),StandardScaler(),grid)\n",
    "    fittedgrid=pipe.fit(X_train, y_train)\n",
    "#Saving the 25 subresults\n",
    "    dfCurrent= pd.DataFrame(grid.cv_results_)\n",
    "    dfInterno = pd.concat([dfInterno, dfCurrent], axis=0)\n",
    "#Saving the best params and the results\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)\n",
    "    #dfBest= pd.concat([dfBest, dfCurrentBest], axis=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76b58c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInterno.to_csv(r\"C:\\Users\\White\\Desktop\\tfg\\generados\\RFEncodedGridSearchCV.csv\", index = None, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c54ee39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.1333 - accuracy: 0.9579\n",
      "Epoch 2/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0511 - accuracy: 0.9849\n",
      "Epoch 3/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0411 - accuracy: 0.9875\n",
      "Epoch 4/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0360 - accuracy: 0.9892\n",
      "Epoch 5/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0346 - accuracy: 0.9899\n",
      "Epoch 6/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0331 - accuracy: 0.9903\n",
      "Epoch 7/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0326 - accuracy: 0.9906\n",
      "Epoch 8/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0315 - accuracy: 0.9909\n",
      "Epoch 9/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0312 - accuracy: 0.9908\n",
      "Epoch 10/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0311 - accuracy: 0.9911\n",
      "Epoch 11/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0295 - accuracy: 0.9914\n",
      "Epoch 12/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0289 - accuracy: 0.9917\n",
      "Epoch 13/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0284 - accuracy: 0.9919\n",
      "Epoch 14/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0276 - accuracy: 0.9920\n",
      "Epoch 15/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0274 - accuracy: 0.9921\n",
      "Epoch 16/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0277 - accuracy: 0.9922\n",
      "Epoch 17/20\n",
      "8348/8348 [==============================] - 13s 1ms/step - loss: 0.0270 - accuracy: 0.9924\n",
      "Epoch 18/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0262 - accuracy: 0.9926\n",
      "Epoch 19/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0266 - accuracy: 0.9924\n",
      "Epoch 20/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0262 - accuracy: 0.9929\n",
      "{'batch_size': 32, 'epochs': 20}\n",
      "0.9978512182065412\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/20\n",
      "4174/4174 [==============================] - 6s 1ms/step - loss: 0.1923 - accuracy: 0.9331\n",
      "Epoch 2/20\n",
      "4174/4174 [==============================] - 6s 1ms/step - loss: 0.0547 - accuracy: 0.9826\n",
      "Epoch 3/20\n",
      "4174/4174 [==============================] - 6s 1ms/step - loss: 0.0445 - accuracy: 0.9856\n",
      "Epoch 4/20\n",
      "4174/4174 [==============================] - 6s 1ms/step - loss: 0.0386 - accuracy: 0.9875\n",
      "Epoch 5/20\n",
      "4174/4174 [==============================] - 6s 1ms/step - loss: 0.0358 - accuracy: 0.9888\n",
      "Epoch 6/20\n",
      "4174/4174 [==============================] - 6s 1ms/step - loss: 0.0336 - accuracy: 0.9896\n",
      "Epoch 7/20\n",
      "4174/4174 [==============================] - 6s 1ms/step - loss: 0.0319 - accuracy: 0.9900\n",
      "Epoch 8/20\n",
      "4174/4174 [==============================] - 6s 1ms/step - loss: 0.0310 - accuracy: 0.9906\n",
      "Epoch 9/20\n",
      "4174/4174 [==============================] - 6s 1ms/step - loss: 0.0301 - accuracy: 0.9909\n",
      "Epoch 10/20\n",
      "4174/4174 [==============================] - 6s 1ms/step - loss: 0.0286 - accuracy: 0.9915\n",
      "Epoch 11/20\n",
      "4174/4174 [==============================] - 6s 1ms/step - loss: 0.0283 - accuracy: 0.9917\n",
      "Epoch 12/20\n",
      "4174/4174 [==============================] - 6s 1ms/step - loss: 0.0276 - accuracy: 0.9920\n",
      "Epoch 13/20\n",
      "4174/4174 [==============================] - 6s 1ms/step - loss: 0.0267 - accuracy: 0.9925\n",
      "Epoch 14/20\n",
      "4174/4174 [==============================] - 6s 1ms/step - loss: 0.0259 - accuracy: 0.9925\n",
      "Epoch 15/20\n",
      "4174/4174 [==============================] - 6s 1ms/step - loss: 0.0247 - accuracy: 0.9931\n",
      "Epoch 16/20\n",
      "4174/4174 [==============================] - 6s 1ms/step - loss: 0.0240 - accuracy: 0.9933\n",
      "Epoch 17/20\n",
      "4174/4174 [==============================] - 6s 1ms/step - loss: 0.0236 - accuracy: 0.9934\n",
      "Epoch 18/20\n",
      "4174/4174 [==============================] - 6s 1ms/step - loss: 0.0229 - accuracy: 0.9938\n",
      "Epoch 19/20\n",
      "4174/4174 [==============================] - 6s 1ms/step - loss: 0.0235 - accuracy: 0.9937\n",
      "Epoch 20/20\n",
      "4174/4174 [==============================] - 6s 1ms/step - loss: 0.0227 - accuracy: 0.9938\n",
      "{'batch_size': 64, 'epochs': 20}\n",
      "0.9971174877987353\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/20\n",
      "8348/8348 [==============================] - ETA: 0s - loss: 0.1203 - accuracy: 0.96 - 12s 1ms/step - loss: 0.1202 - accuracy: 0.9602\n",
      "Epoch 2/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0503 - accuracy: 0.9851\n",
      "Epoch 3/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0437 - accuracy: 0.9877\n",
      "Epoch 4/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0402 - accuracy: 0.9887\n",
      "Epoch 5/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0385 - accuracy: 0.9897\n",
      "Epoch 6/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0372 - accuracy: 0.9899\n",
      "Epoch 7/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0356 - accuracy: 0.9905\n",
      "Epoch 8/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0345 - accuracy: 0.9908\n",
      "Epoch 9/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0344 - accuracy: 0.9910\n",
      "Epoch 10/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0337 - accuracy: 0.9907\n",
      "Epoch 11/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0330 - accuracy: 0.9911\n",
      "Epoch 12/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0330 - accuracy: 0.9911\n",
      "Epoch 13/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0308 - accuracy: 0.9918\n",
      "Epoch 14/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0308 - accuracy: 0.9917\n",
      "Epoch 15/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0302 - accuracy: 0.9919\n",
      "Epoch 16/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0297 - accuracy: 0.9922\n",
      "Epoch 17/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0293 - accuracy: 0.9921\n",
      "Epoch 18/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0283 - accuracy: 0.9924\n",
      "Epoch 19/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0278 - accuracy: 0.9926\n",
      "Epoch 20/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0280 - accuracy: 0.9924\n",
      "{'batch_size': 32, 'epochs': 20}\n",
      "0.9970239011776002\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.1480 - accuracy: 0.9505\n",
      "Epoch 2/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0566 - accuracy: 0.9827\n",
      "Epoch 3/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0464 - accuracy: 0.9861\n",
      "Epoch 4/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0415 - accuracy: 0.9882\n",
      "Epoch 5/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0380 - accuracy: 0.9896\n",
      "Epoch 6/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0359 - accuracy: 0.9904\n",
      "Epoch 7/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0355 - accuracy: 0.9908\n",
      "Epoch 8/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0346 - accuracy: 0.9909\n",
      "Epoch 9/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0344 - accuracy: 0.9908\n",
      "Epoch 10/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0331 - accuracy: 0.9912\n",
      "Epoch 11/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0331 - accuracy: 0.9912\n",
      "Epoch 12/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0331 - accuracy: 0.9911\n",
      "Epoch 13/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0321 - accuracy: 0.9916\n",
      "Epoch 14/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0314 - accuracy: 0.9918\n",
      "Epoch 15/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0311 - accuracy: 0.9917\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0307 - accuracy: 0.9919\n",
      "Epoch 17/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0305 - accuracy: 0.9918\n",
      "Epoch 18/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0299 - accuracy: 0.9920\n",
      "Epoch 19/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0291 - accuracy: 0.9923\n",
      "Epoch 20/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0289 - accuracy: 0.9925\n",
      "{'batch_size': 32, 'epochs': 20}\n",
      "0.9970800555747072\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.1335 - accuracy: 0.9554\n",
      "Epoch 2/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0504 - accuracy: 0.9830\n",
      "Epoch 3/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0418 - accuracy: 0.9860\n",
      "Epoch 4/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0378 - accuracy: 0.9877\n",
      "Epoch 5/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0350 - accuracy: 0.9889\n",
      "Epoch 6/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0323 - accuracy: 0.9901\n",
      "Epoch 7/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0303 - accuracy: 0.9909\n",
      "Epoch 8/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0298 - accuracy: 0.9910\n",
      "Epoch 9/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0287 - accuracy: 0.9916\n",
      "Epoch 10/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0275 - accuracy: 0.9923\n",
      "Epoch 11/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0274 - accuracy: 0.9920\n",
      "Epoch 12/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0257 - accuracy: 0.9928\n",
      "Epoch 13/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0261 - accuracy: 0.9925\n",
      "Epoch 14/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0260 - accuracy: 0.9927\n",
      "Epoch 15/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0251 - accuracy: 0.9929\n",
      "Epoch 16/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0246 - accuracy: 0.9931\n",
      "Epoch 17/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0252 - accuracy: 0.9930\n",
      "Epoch 18/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0241 - accuracy: 0.9933\n",
      "Epoch 19/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0233 - accuracy: 0.9936\n",
      "Epoch 20/20\n",
      "8348/8348 [==============================] - 12s 1ms/step - loss: 0.0238 - accuracy: 0.9936\n",
      "{'batch_size': 32, 'epochs': 20}\n",
      "0.9971474365349169\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "X = encoded_X\n",
    "y = encoded_y\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "# Initialising the CNN\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=31, kernel_size=3, activation='relu'))\n",
    "    #model.add(Conv1D(filters=31, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation=\"sigmoid\")) # binary activation output\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model)\n",
    "\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [32, 64]\n",
    "#optimizer= [\"RMSprop\", \"adam\"]\n",
    "epochs = [10, 20]\n",
    "#dropout = [0, 0.1, 0.2]\n",
    "p_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "scoring = {'accuracy', \"precision\", \"recall\",  \"f1\"}\n",
    "dfInterno=pd.DataFrame()\n",
    "\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# Nested CV with parameter optimization\n",
    "for train_index, test_index in outer_cv.split(X,y):\n",
    "\n",
    "    X_train,X_test= X[train_index,:], X[test_index,:] \n",
    "    y_train,y_test= y[train_index], y[test_index]\n",
    "    \n",
    "    X_train=MinMaxScaler().fit_transform(X_train)\n",
    "    X_train=MinMaxScaler().fit_transform(X_train)\n",
    "\n",
    "    X_test=MinMaxScaler().fit_transform(X_test)\n",
    "    X_test=MinMaxScaler().fit_transform(X_test)\n",
    "\n",
    "    #X_train=X_train.to_numpy()\n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    #X_test=X_test.to_numpy()\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "    \n",
    "    grid = GridSearchCV(model,return_train_score=True,scoring=scoring, refit=\"accuracy\",param_grid=p_grid, n_jobs=-1, cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=1), verbose=4)\n",
    "    fittedgrid=grid.fit(X_train, y_train)\n",
    "#Saving the 25 subresults\n",
    "    dfCurrent= pd.DataFrame(grid.cv_results_)\n",
    "    dfInterno = pd.concat([dfInterno, dfCurrent], axis=0)\n",
    "#Saving the best params and the results\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)\n",
    "    #dfBest= pd.concat([dfBest, dfCurrentBest], axis=0)      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9947c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInterno.to_csv(r\"C:\\Users\\White\\Desktop\\tfg\\generados\\CNNEncodedGridSearchCVAtaques.csv\", index = None, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca980647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
