{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d28182ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs\n",
    "import mglearn\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Gráficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "#style.use('ggplot') or plt.style.use('ggplot')\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Configuración warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Random global\n",
    "seed = 12345\n",
    "rng = np.random.default_rng(seed)  # can be called without a seed\n",
    "rng.random()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv (r\"C:\\Users\\White\\Desktop\\tfg\\generados\\RFECved.csv\")\n",
    "dfNon = pd.read_csv (r\"C:\\Users\\White\\Desktop\\tfg\\generados\\scaled.csv\")\n",
    "df2 = pd.read_csv (r\"C:\\Users\\White\\Desktop\\tfg\\generados\\Deoutliers2.csv\")\n",
    "dfR = pd.read_csv (r\"C:\\Users\\White\\Desktop\\tfg\\generados\\Raw-ishDf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5541837",
   "metadata": {},
   "source": [
    "# GaussianNB as a baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d904c8",
   "metadata": {},
   "source": [
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee837515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "{'var_smoothing': 1e-08}\n",
      "0.9864184815803458\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "{'var_smoothing': 1e-08}\n",
      "0.986673067244306\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "{'var_smoothing': 1e-08}\n",
      "0.9863698248252482\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "{'var_smoothing': 1e-05}\n",
      "0.9841536627722809\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "{'var_smoothing': 1e-08}\n",
      "0.9847713463556648\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "X = df.copy()\n",
    "X[\"LabelA\"]=df2[\"LabelA\"]\n",
    "y = X.pop(\"LabelA\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=42)\n",
    "\n",
    "dfInterno=pd.DataFrame()\n",
    "dfBest=pd.DataFrame()\n",
    "\n",
    "#baseline parameters\n",
    "p_grid = { \n",
    "    'var_smoothing': [1e-8, 1e-7, 1e-6, 1e-5, 1e-4]\n",
    "}\n",
    "\n",
    "scoring = {'accuracy', \"precision\", \"recall\",  \"f1\"}\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# Nested CV with parameter optimization\n",
    "for train_index, test_index in outer_cv.split(X,y):\n",
    "    X_train,X_test= X.iloc[train_index,:], X.iloc[test_index,:] \n",
    "    y_train,y_test= y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    grid = GridSearchCV(GaussianNB(),return_train_score=True,scoring=scoring, refit='accuracy', param_grid=p_grid, n_jobs=-1, cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=1), verbose=3)\n",
    "    pipe= make_pipeline(MinMaxScaler(),StandardScaler(),grid)\n",
    "    fittedgrid=pipe.fit(X_train, y_train)\n",
    "#Saving the 25 subresults\n",
    "    dfCurrent= pd.DataFrame(grid.cv_results_)\n",
    "    dfInterno = pd.concat([dfInterno, dfCurrent], axis=0)\n",
    "#Saving the best params and the results\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)\n",
    "    #dfBest= pd.concat([dfBest, dfCurrentBest], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21d0ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInterno.to_csv(r\"C:\\Users\\White\\Desktop\\tfg\\generados\\GaussianGridSearchCV.csv\", index = None, header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b692e6",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "315bd770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'max_depth': 5, 'n_estimators': 200}\n",
      "0.999363601040338\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'max_depth': 5, 'n_estimators': 200}\n",
      "0.9994085225680325\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'max_depth': 5, 'n_estimators': 100}\n",
      "0.9994010361372409\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'max_depth': 5, 'n_estimators': 200}\n",
      "0.9994197534754818\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'max_depth': 5, 'n_estimators': 200}\n",
      "0.9993823190792801\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "X = df.copy()\n",
    "X[\"LabelA\"]=df2[\"LabelA\"]\n",
    "y = X.pop(\"LabelA\")\n",
    "\n",
    "dfInterno=pd.DataFrame()\n",
    "# define the model with default hyperparameters\n",
    "model=RandomForestClassifier(random_state=42)\n",
    "scoring = {'accuracy', \"precision\", \"recall\",  \"f1\"}\n",
    "\n",
    "# define the grid of values to search\n",
    "p_grid = { \n",
    "    'n_estimators': [100, 200],\n",
    "    #Empirical good default values [...] max_features=sqrt(n_features) for classification tasks\n",
    "   # 'max_features': [\"auto\", \"sqrt\"],\n",
    "    'max_depth' : [3,4,5],\n",
    "    #'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# Nested CV with parameter optimization\n",
    "for train_index, test_index in outer_cv.split(X,y):\n",
    "    X_train,X_test= X.iloc[train_index,:], X.iloc[test_index,:] \n",
    "    y_train,y_test= y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "    grid = GridSearchCV(model,return_train_score=True,scoring=scoring, refit=\"accuracy\",param_grid=p_grid, n_jobs=-1, cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=1), verbose=4)\n",
    "    pipe= make_pipeline(MinMaxScaler(),StandardScaler(),grid)\n",
    "    fittedgrid=pipe.fit(X_train, y_train)\n",
    "#Saving the 25 subresults\n",
    "    dfCurrent= pd.DataFrame(grid.cv_results_)\n",
    "    dfInterno = pd.concat([dfInterno, dfCurrent], axis=0)\n",
    "#Saving the best params and the results\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)\n",
    "    #dfBest= pd.concat([dfBest, dfCurrentBest], axis=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0caeff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInterno.to_csv(r\"C:\\Users\\White\\Desktop\\tfg\\generados\\RForestGridSearchCV.csv\", index = None, header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60925434",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0b040d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'learning_rate': 0.1, 'n_estimators': 200}\n",
      "0.9988395072312443\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'learning_rate': 0.1, 'n_estimators': 200}\n",
      "0.9987758670339766\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'learning_rate': 0.1, 'n_estimators': 200}\n",
      "0.9988170456966257\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'learning_rate': 0.1, 'n_estimators': 200}\n",
      "0.9987983276576836\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'learning_rate': 0.1, 'n_estimators': 200}\n",
      "0.9988170470279579\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "X = df.copy()\n",
    "X[\"LabelA\"]=df2[\"LabelA\"]\n",
    "y = X.pop(\"LabelA\")\n",
    "\n",
    "dfInterno=pd.DataFrame()\n",
    "scoring = {'accuracy', \"precision\", \"recall\",  \"f1\"}\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# define the model with default hyperparameters\n",
    "model = AdaBoostClassifier()\n",
    "# define the grid of values to search\n",
    "p_grid = dict()\n",
    "p_grid['n_estimators'] = [100,200]\n",
    "p_grid['learning_rate'] = [0.1,0.001,0.0001]\n",
    "\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# Nested CV with parameter optimization\n",
    "for train_index, test_index in outer_cv.split(X,y):\n",
    "    X_train,X_test= X.iloc[train_index,:], X.iloc[test_index,:] \n",
    "    y_train,y_test= y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "    grid = GridSearchCV(model,return_train_score=True,scoring=scoring, refit=\"accuracy\",param_grid=p_grid, n_jobs=-1, cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=1), verbose=4)\n",
    "    pipe= make_pipeline(MinMaxScaler(),StandardScaler(),grid)\n",
    "    fittedgrid=pipe.fit(X_train, y_train)\n",
    "#Saving the 25 subresults\n",
    "    dfCurrent= pd.DataFrame(grid.cv_results_)\n",
    "    dfInterno = pd.concat([dfInterno, dfCurrent], axis=0)\n",
    "#Saving the best params and the results\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)\n",
    "    #dfBest= pd.concat([dfBest, dfCurrentBest], axis=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17231836",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInterno.to_csv(r\"C:\\Users\\White\\Desktop\\tfg\\generados\\AdaboostGridSearchCV.csv\", index = None, header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9266a08",
   "metadata": {},
   "source": [
    "# LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70877f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'C': 1, 'tol': 0.0001}\n",
      "0.9988731992528914\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'C': 1, 'tol': 0.001}\n",
      "0.998966786714868\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'C': 1, 'tol': 0.0001}\n",
      "0.998974273916431\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'C': 1, 'tol': 0.001}\n",
      "0.9989443251101795\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "{'C': 1, 'tol': 0.001}\n",
      "0.9988769435894091\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "X = df.copy()\n",
    "X[\"LabelA\"]=df2[\"LabelA\"]\n",
    "y = X.pop(\"LabelA\")\n",
    "dfInterno=pd.DataFrame()\n",
    "\n",
    "X_trian, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=42)\n",
    "\n",
    "scoring = {'accuracy', \"precision\", \"recall\",  \"f1\"}\n",
    "\n",
    "# define the model with default hyperparameters\n",
    "model = LinearSVC()\n",
    "# define the grid of values to search\n",
    "p_grid = {\"tol\": [1e-3, 1e-4], \"C\": [1, 10, 100]}\n",
    "\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# Nested CV with parameter optimization\n",
    "for train_index, test_index in outer_cv.split(X,y):\n",
    "    X_train,X_test= X.iloc[train_index,:], X.iloc[test_index,:] \n",
    "    y_train,y_test= y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "    grid = GridSearchCV(model,return_train_score=True,scoring=scoring, refit=\"accuracy\",param_grid=p_grid, n_jobs=-1, cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=1), verbose=4)\n",
    "    pipe= make_pipeline(MinMaxScaler(),StandardScaler(),grid)\n",
    "    fittedgrid=pipe.fit(X_train, y_train)\n",
    "#Saving the 25 subresults\n",
    "    dfCurrent= pd.DataFrame(grid.cv_results_)\n",
    "    dfInterno = pd.concat([dfInterno, dfCurrent], axis=0)\n",
    "#Saving the best params and the results\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)\n",
    "    #dfBest= pd.concat([dfBest, dfCurrentBest], axis=0)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "811bb930",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInterno.to_csv(r\"C:\\Users\\White\\Desktop\\tfg\\generados\\LinearSVCGridSearchCV.csv\", index = None, header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8279a7",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc46bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = df.copy()\n",
    "X[\"LabelA\"]=df2[\"LabelA\"]\n",
    "\n",
    "y = X.pop(\"LabelA\")\n",
    "\n",
    "#Autoencoder\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(learning_rate= 0.0001):\n",
    "    # Building the Input Layer\n",
    "    input_layer = Input(shape =(X.shape[1], ))\n",
    "    model = Sequential()\n",
    "\n",
    "    # Building the Encoder network\n",
    "    encoded = Dense(100, activation ='tanh',\n",
    "                activity_regularizer = regularizers.l1(10e-5))(input_layer)\n",
    "    encoded = Dense(50, activation ='tanh',\n",
    "                activity_regularizer = regularizers.l1(10e-5))(encoded)\n",
    "    encoded = Dense(25, activation ='tanh',\n",
    "                activity_regularizer = regularizers.l1(10e-5))(encoded)\n",
    "    encoded = Dense(12, activation ='tanh',\n",
    "                activity_regularizer = regularizers.l1(10e-5))(encoded)\n",
    "    encoded = Dense(6, activation ='relu')(encoded)\n",
    "  \n",
    "    # Building the Decoder network\n",
    "    decoded = Dense(12, activation ='tanh')(encoded)\n",
    "    decoded = Dense(25, activation ='tanh')(decoded)\n",
    "    decoded = Dense(50, activation ='tanh')(decoded)\n",
    "    decoded = Dense(100, activation ='tanh')(decoded)\n",
    "  \n",
    "    # Building the Output Layer\n",
    "    output_layer = Dense(X.shape[1], activation ='relu')(decoded)\n",
    "    autoencoder = Model(input_layer, output_layer)\n",
    "\n",
    "    #optimizer=tf.keras.optimizers.Adadelta(lr=0.1, rho=0.95, epsilon=None, decay=0.0)\n",
    "\n",
    "    # Compile model\n",
    "    autoencoder.compile(optimizer =\"adadelta\", loss =\"mse\")\n",
    "\n",
    "    return autoencoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model)\n",
    "\n",
    "scoring = {'accuracy', \"precision\", \"recall\",  \"f1\"}\n",
    "dfInterno=pd.DataFrame()\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [100, 200]\n",
    "epochs = [10,20]\n",
    "\n",
    "p_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# Nested CV with parameter optimization\n",
    "for train_index, test_index in outer_cv.split(X,y):\n",
    "    X_train,X_test= X.iloc[train_index,:], X.iloc[test_index,:] \n",
    "    y_train,y_test= y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    grid = GridSearchCV(model,return_train_score=True,scoring=scoring, refit=\"accuracy\",param_grid=p_grid, n_jobs=-1, cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=1), verbose=4)\n",
    "    pipe= make_pipeline(MinMaxScaler(),StandardScaler(),grid)\n",
    "    fittedgrid=pipe.fit(X_train, y_train)\n",
    "#Saving the 25 subresults\n",
    "    dfCurrent= pd.DataFrame(grid.cv_results_)\n",
    "    dfInterno = pd.concat([dfInterno, dfCurrent], axis=0)\n",
    "#Saving the best params and the results\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)\n",
    "    #dfBest= pd.concat([dfBest, dfCurrentBest], axis=0)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10cb0872",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInterno.to_csv(r\"C:\\Users\\White\\Desktop\\tfg\\generados\\AutoencoderGridSearchCV.csv\", index = None, header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733076a2",
   "metadata": {},
   "source": [
    "# TensorBoard tryout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39c672d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "8348/8348 [==============================] - 10s 1ms/step - loss: 0.0501 - accuracy: 0.9900\n",
      "2087/2087 [==============================] - 2s 703us/step - loss: 0.0019 - accuracy: 0.9994\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "8348/8348 [==============================] - 9s 1ms/step - loss: 0.0617 - accuracy: 0.9872\n",
      "2087/2087 [==============================] - 2s 732us/step - loss: 0.0092 - accuracy: 0.9977\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "8348/8348 [==============================] - 9s 1ms/step - loss: 0.0346 - accuracy: 0.9936\n",
      "2087/2087 [==============================] - 2s 704us/step - loss: 0.0018 - accuracy: 0.9996\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "8348/8348 [==============================] - 9s 1ms/step - loss: 0.0762 - accuracy: 0.9881\n",
      "2087/2087 [==============================] - 2s 701us/step - loss: 0.0100 - accuracy: 0.9979\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "8348/8348 [==============================] - 10s 1ms/step - loss: 0.0264 - accuracy: 0.9951\n",
      "2087/2087 [==============================] - 2s 702us/step - loss: 8.0466e-04 - accuracy: 0.9999\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "8348/8348 [==============================] - 9s 1ms/step - loss: 0.0366 - accuracy: 0.9933\n",
      "2087/2087 [==============================] - 2s 707us/step - loss: 0.0058 - accuracy: 0.9980\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 32, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "8348/8348 [==============================] - 10s 1ms/step - loss: 0.0319 - accuracy: 0.9933\n",
      "2087/2087 [==============================] - 2s 697us/step - loss: 0.0019 - accuracy: 0.9997\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 32, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "8348/8348 [==============================] - 9s 1ms/step - loss: 0.0504 - accuracy: 0.9899\n",
      "2087/2087 [==============================] - 2s 706us/step - loss: 0.0084 - accuracy: 0.9981\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "  )\n",
    "\n",
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    accuracy = train_test_model(hparams)\n",
    "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    "def train_test_model(hparams):\n",
    "  model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax),\n",
    "  ])\n",
    "  model.compile(\n",
    "      optimizer=hparams[HP_OPTIMIZER],\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['accuracy'],\n",
    "  )\n",
    "\n",
    "  model.fit(X_train, y_train, epochs=1) # Run with 1 epoch to speed things up for demo purposes\n",
    "  _, accuracy = model.evaluate(X_test, y_test)\n",
    "  return accuracy\n",
    "\n",
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "      hparams = {\n",
    "          HP_NUM_UNITS: num_units,\n",
    "          HP_DROPOUT: dropout_rate,\n",
    "          HP_OPTIMIZER: optimizer,\n",
    "      }\n",
    "      run_name = \"run-%d\" % session_num\n",
    "      print('--- Starting trial: %s' % run_name)\n",
    "      print({h.name: hparams[h] for h in hparams})\n",
    "      run('logs/hparam_tuning/' + run_name, hparams)\n",
    "      session_num += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9dd29866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b7a270c9c62eb39\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b7a270c9c62eb39\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36231934",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad0ed91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 11s 35ms/step - loss: 0.2955 - acc: 0.8650\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 0.1444 - acc: 0.9482\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.1083 - acc: 0.9638\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0934 - acc: 0.9733\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0811 - acc: 0.9786\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0731 - acc: 0.9816\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0690 - acc: 0.9827\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0601 - acc: 0.9847\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0514 - acc: 0.9864\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0395 - acc: 0.9892\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0322 - acc: 0.9907\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0434 - acc: 0.9866\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0247 - acc: 0.9925\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0213 - acc: 0.9936\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0412 - acc: 0.9874\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0223 - acc: 0.9930\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0184 - acc: 0.9947\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0168 - acc: 0.9954\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 0.0160 - acc: 0.9956\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 0.0137 - acc: 0.9965\n",
      "{'batch_size': 1000, 'epochs': 20}\n",
      "0.9978549593198338\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 10s 33ms/step - loss: 0.2756 - acc: 0.8880\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.1325 - acc: 0.9470\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0901 - acc: 0.9712\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0661 - acc: 0.9815\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0564 - acc: 0.9843\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0482 - acc: 0.9868: 0s - loss: 0.048\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0422 - acc: 0.9887\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0357 - acc: 0.9906\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0286 - acc: 0.9926: 1s - loss: 0.0299 - acc: 0.992 - ETA: 1s -\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0202 - acc: 0.9950\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0142 - acc: 0.9971\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0119 - acc: 0.9977\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0104 - acc: 0.9980\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0095 - acc: 0.9981\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0084 - acc: 0.9983\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0078 - acc: 0.9984\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0070 - acc: 0.9985\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0068 - acc: 0.9987\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0059 - acc: 0.9988\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0057 - acc: 0.9989\n",
      "{'batch_size': 1000, 'epochs': 20}\n",
      "0.9983977696263271\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 11s 33ms/step - loss: 0.2894 - acc: 0.8778 \n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.1487 - acc: 0.9409\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0870 - acc: 0.9706\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0667 - acc: 0.9773\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0558 - acc: 0.9820\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0493 - acc: 0.9845\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0417 - acc: 0.9866\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0367 - acc: 0.9880\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0305 - acc: 0.9902\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0261 - acc: 0.9919\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0221 - acc: 0.9934\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0185 - acc: 0.9952: 0s - loss: 0.0186 - \n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0156 - acc: 0.9966: \n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0140 - acc: 0.9972\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0116 - acc: 0.9976: 3s -  - ETA: 1s -\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0110 - acc: 0.9978\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0107 - acc: 0.9979\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0096 - acc: 0.9981\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0100 - acc: 0.9980\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0085 - acc: 0.9984\n",
      "{'batch_size': 1000, 'epochs': 20}\n",
      "0.9953318299907817\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 10s 33ms/step - loss: 0.2734 - acc: 0.8954\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.1332 - acc: 0.9469: 2s - loss: 0.1417 - ac - ETA\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0906 - acc: 0.9708\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 0.0652 - acc: 0.9805\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0539 - acc: 0.9841\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0418 - acc: 0.9877\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0245 - acc: 0.9935\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0172 - acc: 0.9963\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0139 - acc: 0.9974: 0s - loss: 0.0139 - a\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0123 - acc: 0.9978\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0111 - acc: 0.9982\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0103 - acc: 0.9984\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0098 - acc: 0.9984\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0096 - acc: 0.9984: 0s - loss: 0.0096 - acc: 0. - ETA: 0s - loss: 0.0095 - acc: 0.\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0089 - acc: 0.9985\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0086 - acc: 0.9985: 0s - loss: 0.0085 - \n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 0.0080 - acc: 0.9987: 0s - loss: 0.008\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0076 - acc: 0.9987\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.0072 - acc: 0.9988\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0411 - acc: 0.9939\n",
      "{'batch_size': 1000, 'epochs': 20}\n",
      "0.9981544400950565\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 10s 33ms/step - loss: 0.2747 - acc: 0.8950\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.1444 - acc: 0.9489\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 0.1006 - acc: 0.9647\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 0.0625 - acc: 0.9831\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 0.0512 - acc: 0.9857\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.0453 - acc: 0.9867\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 0.0396 - acc: 0.9885: \n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 0.0334 - acc: 0.9910\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 0.0241 - acc: 0.9930\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 0.0192 - acc: 0.9955\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 0.0154 - acc: 0.9968\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 0.0132 - acc: 0.9975\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 0.0132 - acc: 0.9974\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 0.0115 - acc: 0.9977: 0s - loss: 0.0118 - acc\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 0.0103 - acc: 0.9979\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 0.0099 - acc: 0.9980\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 0.0093 - acc: 0.9980\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 0.0088 - acc: 0.9982\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 0.0078 - acc: 0.9983\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 8s 32ms/step - loss: 0.0077 - acc: 0.9983\n",
      "{'batch_size': 1000, 'epochs': 20}\n",
      "0.9981432088372564\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, LSTM, Dropout, Input\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "X = df.copy()\n",
    "X[\"LabelA\"]=df2[\"LabelA\"]\n",
    "y = X.pop(\"LabelA\")\n",
    "\n",
    "dfInterno=pd.DataFrame()\n",
    "\n",
    "hidden_nodes = int(2/3 * (X.shape[1] + 1))\n",
    "#print(f\"The number of hidden nodes is {hidden_nodes}.\")\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "# Initialising the RNN\n",
    "def create_model():\n",
    "    #Initializing the RNN\n",
    "    model = Sequential()\n",
    "    #Adding the first LSTM layer and dropout \n",
    "    model.add(LSTM(units=21, return_sequences=False, input_shape=(30, 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    #Adding the output layer\n",
    "    model.add(Dense(units=1,activation='sigmoid'))\n",
    "    #Output is two classes with only one present at a time. \n",
    "    #Softmax allows the model to interpret the outputs as probabilities\n",
    "\n",
    "    #Compiling the model without training\n",
    "    from tensorflow.keras.optimizers import SGD\n",
    "    opt = SGD(lr=0.01)\n",
    "\n",
    "    model.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\", metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model)\n",
    "\n",
    "\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [1000,5000]\n",
    "epochs = [10, 20]\n",
    "\n",
    "p_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "scoring = {'accuracy', \"precision\", \"recall\",  \"f1\"}\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# Nested CV with parameter optimization\n",
    "for train_index, test_index in outer_cv.split(X,y):\n",
    "    X_train,X_test= X.iloc[train_index,:], X.iloc[test_index,:] \n",
    "    y_train,y_test= y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    grid = GridSearchCV(model,return_train_score=True,scoring=scoring, refit=\"accuracy\",param_grid=p_grid, n_jobs=-1, cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=1), verbose=4)\n",
    "    \n",
    "    pipe= make_pipeline(MinMaxScaler(),StandardScaler(),grid)\n",
    "    fittedgrid=pipe.fit(X_train, y_train)\n",
    "#Saving the 25 subresults\n",
    "    dfCurrent= pd.DataFrame(grid.cv_results_)\n",
    "    dfInterno = pd.concat([dfInterno, dfCurrent], axis=0)\n",
    "#Saving the best params and the results\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)\n",
    "    #dfBest= pd.concat([dfBest, dfCurrentBest], axis=0)      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a0d00ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInterno.to_csv(r\"C:\\Users\\White\\Desktop\\tfg\\generados\\RNNGridSearchCV.csv\", index = None, header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ca20d1",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e52825d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/20\n",
      "8348/8348 [==============================] - 15s 2ms/step - loss: 0.0525 - accuracy: 0.9827\n",
      "Epoch 2/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0208 - accuracy: 0.9949\n",
      "Epoch 3/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0189 - accuracy: 0.9956\n",
      "Epoch 4/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0182 - accuracy: 0.9958\n",
      "Epoch 5/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0169 - accuracy: 0.9961\n",
      "Epoch 6/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0163 - accuracy: 0.9963\n",
      "Epoch 7/20\n",
      "8348/8348 [==============================] - 15s 2ms/step - loss: 0.0167 - accuracy: 0.9961\n",
      "Epoch 8/20\n",
      "8348/8348 [==============================] - 15s 2ms/step - loss: 0.0163 - accuracy: 0.9963\n",
      "Epoch 9/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0160 - accuracy: 0.9964\n",
      "Epoch 10/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0160 - accuracy: 0.9964\n",
      "Epoch 11/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0154 - accuracy: 0.9966\n",
      "Epoch 12/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0149 - accuracy: 0.9966\n",
      "Epoch 13/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0148 - accuracy: 0.9966\n",
      "Epoch 14/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0148 - accuracy: 0.9966\n",
      "Epoch 15/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0142 - accuracy: 0.9967\n",
      "Epoch 16/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0140 - accuracy: 0.9967\n",
      "Epoch 17/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0141 - accuracy: 0.9966\n",
      "Epoch 18/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0134 - accuracy: 0.9968\n",
      "Epoch 19/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0131 - accuracy: 0.9968\n",
      "Epoch 20/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0129 - accuracy: 0.9968\n",
      "{'batch_size': 32, 'epochs': 20}\n",
      "0.9985624869395882\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/20\n",
      "4174/4174 [==============================] - 10s 2ms/step - loss: 0.0684 - accuracy: 0.9762\n",
      "Epoch 2/20\n",
      "4174/4174 [==============================] - 10s 2ms/step - loss: 0.0216 - accuracy: 0.9943\n",
      "Epoch 3/20\n",
      "4174/4174 [==============================] - 10s 2ms/step - loss: 0.0186 - accuracy: 0.9957\n",
      "Epoch 4/20\n",
      "4174/4174 [==============================] - 10s 2ms/step - loss: 0.0171 - accuracy: 0.9959\n",
      "Epoch 5/20\n",
      "4174/4174 [==============================] - 10s 2ms/step - loss: 0.0161 - accuracy: 0.9964\n",
      "Epoch 6/20\n",
      "4174/4174 [==============================] - 10s 2ms/step - loss: 0.0153 - accuracy: 0.9965\n",
      "Epoch 7/20\n",
      "4174/4174 [==============================] - 10s 2ms/step - loss: 0.0147 - accuracy: 0.9967\n",
      "Epoch 8/20\n",
      "4174/4174 [==============================] - 10s 2ms/step - loss: 0.0144 - accuracy: 0.9966\n",
      "Epoch 9/20\n",
      "4174/4174 [==============================] - 10s 2ms/step - loss: 0.0138 - accuracy: 0.9968\n",
      "Epoch 10/20\n",
      "4174/4174 [==============================] - 10s 2ms/step - loss: 0.0138 - accuracy: 0.9967\n",
      "Epoch 11/20\n",
      "4174/4174 [==============================] - 10s 2ms/step - loss: 0.0138 - accuracy: 0.9967\n",
      "Epoch 12/20\n",
      "4174/4174 [==============================] - 10s 2ms/step - loss: 0.0130 - accuracy: 0.9970\n",
      "Epoch 13/20\n",
      "4174/4174 [==============================] - 10s 2ms/step - loss: 0.0131 - accuracy: 0.9969\n",
      "Epoch 14/20\n",
      "4174/4174 [==============================] - 10s 2ms/step - loss: 0.0129 - accuracy: 0.9970\n",
      "Epoch 15/20\n",
      "4174/4174 [==============================] - 10s 2ms/step - loss: 0.0131 - accuracy: 0.9970\n",
      "Epoch 16/20\n",
      "4174/4174 [==============================] - 10s 2ms/step - loss: 0.0125 - accuracy: 0.9970\n",
      "Epoch 17/20\n",
      "4174/4174 [==============================] - 10s 2ms/step - loss: 0.0123 - accuracy: 0.9971\n",
      "Epoch 18/20\n",
      "4174/4174 [==============================] - 10s 2ms/step - loss: 0.0121 - accuracy: 0.9972\n",
      "Epoch 19/20\n",
      "4174/4174 [==============================] - 10s 2ms/step - loss: 0.0114 - accuracy: 0.9972\n",
      "Epoch 20/20\n",
      "4174/4174 [==============================] - 10s 2ms/step - loss: 0.0116 - accuracy: 0.9973\n",
      "{'batch_size': 64, 'epochs': 20}\n",
      "0.9985662295944231\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/10\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0523 - accuracy: 0.9824\n",
      "Epoch 2/10\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0191 - accuracy: 0.9954\n",
      "Epoch 3/10\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0174 - accuracy: 0.9960\n",
      "Epoch 4/10\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0165 - accuracy: 0.9959\n",
      "Epoch 5/10\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0162 - accuracy: 0.9962\n",
      "Epoch 6/10\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0154 - accuracy: 0.9964\n",
      "Epoch 7/10\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0152 - accuracy: 0.9965\n",
      "Epoch 8/10\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0154 - accuracy: 0.9964\n",
      "Epoch 9/10\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0153 - accuracy: 0.9964\n",
      "Epoch 10/10\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0149 - accuracy: 0.9964\n",
      "{'batch_size': 32, 'epochs': 10}\n",
      "0.998498845200778\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0570 - accuracy: 0.9801\n",
      "Epoch 2/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0248 - accuracy: 0.9931\n",
      "Epoch 3/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0222 - accuracy: 0.9940\n",
      "Epoch 4/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0208 - accuracy: 0.9946\n",
      "Epoch 5/20\n",
      "8348/8348 [==============================] - 14s 2ms/step - loss: 0.0200 - accuracy: 0.9948\n",
      "Epoch 6/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0196 - accuracy: 0.9950\n",
      "Epoch 7/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0189 - accuracy: 0.9953\n",
      "Epoch 8/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0181 - accuracy: 0.9954\n",
      "Epoch 9/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0183 - accuracy: 0.9952\n",
      "Epoch 10/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0174 - accuracy: 0.9957\n",
      "Epoch 11/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0164 - accuracy: 0.9958\n",
      "Epoch 12/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0163 - accuracy: 0.9959\n",
      "Epoch 13/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0165 - accuracy: 0.9957\n",
      "Epoch 14/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0159 - accuracy: 0.9959\n",
      "Epoch 15/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0155 - accuracy: 0.9961\n",
      "Epoch 16/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0150 - accuracy: 0.9963\n",
      "Epoch 17/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0147 - accuracy: 0.9964\n",
      "Epoch 18/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0141 - accuracy: 0.9965\n",
      "Epoch 19/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0133 - accuracy: 0.9967\n",
      "Epoch 20/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0134 - accuracy: 0.9967\n",
      "{'batch_size': 32, 'epochs': 20}\n",
      "0.9986448437043258\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0497 - accuracy: 0.9832\n",
      "Epoch 2/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0192 - accuracy: 0.9955\n",
      "Epoch 3/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0180 - accuracy: 0.9960\n",
      "Epoch 4/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0175 - accuracy: 0.9961\n",
      "Epoch 5/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0165 - accuracy: 0.9964\n",
      "Epoch 6/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0156 - accuracy: 0.9966\n",
      "Epoch 7/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0155 - accuracy: 0.9964\n",
      "Epoch 8/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0153 - accuracy: 0.9967\n",
      "Epoch 9/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0153 - accuracy: 0.9965\n",
      "Epoch 10/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0150 - accuracy: 0.9967\n",
      "Epoch 11/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0147 - accuracy: 0.9968\n",
      "Epoch 12/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0144 - accuracy: 0.9966\n",
      "Epoch 13/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0145 - accuracy: 0.9968\n",
      "Epoch 14/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0144 - accuracy: 0.9968\n",
      "Epoch 15/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0145 - accuracy: 0.9968\n",
      "Epoch 16/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0147 - accuracy: 0.9967\n",
      "Epoch 17/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0146 - accuracy: 0.9966\n",
      "Epoch 18/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0146 - accuracy: 0.9967\n",
      "Epoch 19/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0143 - accuracy: 0.9967\n",
      "Epoch 20/20\n",
      "8348/8348 [==============================] - 13s 2ms/step - loss: 0.0147 - accuracy: 0.9965\n",
      "{'batch_size': 32, 'epochs': 20}\n",
      "0.9986336141982786\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "X = df.copy()\n",
    "X[\"LabelA\"]=df2[\"LabelA\"]\n",
    "y = X.pop(\"LabelA\")\n",
    "\n",
    "\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "# Initialising the CNN\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=31, kernel_size=3, activation='relu'))\n",
    "    #model.add(Conv1D(filters=31, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation=\"sigmoid\")) # binary activation output\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model)\n",
    "\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [32, 64]\n",
    "#optimizer= [\"RMSprop\", \"adam\"]\n",
    "epochs = [10, 20]\n",
    "#dropout = [0, 0.1, 0.2]\n",
    "p_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "scoring = {'accuracy', \"precision\", \"recall\",  \"f1\"}\n",
    "dfInterno=pd.DataFrame()\n",
    "\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# Nested CV with parameter optimization\n",
    "for train_index, test_index in outer_cv.split(X,y):\n",
    "\n",
    "    X_train,X_test= X.iloc[train_index,:], X.iloc[test_index,:] \n",
    "    y_train,y_test= y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    X_train=MinMaxScaler().fit_transform(X_train)\n",
    "    X_train=MinMaxScaler().fit_transform(X_train)\n",
    "\n",
    "    X_test=MinMaxScaler().fit_transform(X_test)\n",
    "    X_test=MinMaxScaler().fit_transform(X_test)\n",
    "\n",
    "    #X_train=X_train.to_numpy()\n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    #X_test=X_test.to_numpy()\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "    \n",
    "    grid = GridSearchCV(model,return_train_score=True,scoring=scoring, refit=\"accuracy\",param_grid=p_grid, n_jobs=-1, cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=1), verbose=4)\n",
    "    fittedgrid=grid.fit(X_train, y_train)\n",
    "#Saving the 25 subresults\n",
    "    dfCurrent= pd.DataFrame(grid.cv_results_)\n",
    "    dfInterno = pd.concat([dfInterno, dfCurrent], axis=0)\n",
    "#Saving the best params and the results\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)\n",
    "    #dfBest= pd.concat([dfBest, dfCurrentBest], axis=0)      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8396a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInterno.to_csv(r\"C:\\Users\\White\\Desktop\\tfg\\generados\\CNNGridSearchCV.csv\", index = None, header=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
