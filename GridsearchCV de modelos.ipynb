{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d28182ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs\n",
    "import mglearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Gráficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "#style.use('ggplot') or plt.style.use('ggplot')\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configuración warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#Random global\n",
    "seed = 12345\n",
    "rng = np.random.default_rng(seed)  # can be called without a seed\n",
    "rng.random()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv (r\"C:\\Users\\White\\Desktop\\tfg\\generados\\RFECved.csv\")\n",
    "df2 = pd.read_csv (r\"C:\\Users\\White\\Desktop\\tfg\\generados\\scaled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4336e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "X = df.copy()\n",
    "X[\"LabelA\"]=df2[\"LabelA\"]\n",
    "y = X.pop(\"LabelA\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5541837",
   "metadata": {},
   "source": [
    "# GaussianNB as a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee837515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "X = df.copy()\n",
    "X[\"LabelA\"]=df2[\"LabelA\"]\n",
    "y = X.pop(\"LabelA\")\n",
    "\n",
    "#because only var_smoothing can be 'tuned'\n",
    "#do a cross validation on different var_smoothing values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=42)\n",
    "\n",
    "\n",
    "accuracy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1_score=[]\n",
    "confusion_matrix=[]\n",
    "time=[]\n",
    "best_params=[]\n",
    "\n",
    "#baseline parameters\n",
    "\n",
    "p_grid = { \n",
    "    'var_smoothing': [1e-8, 1e-7, 1e-6, 1e-5, 1e-4]\n",
    "}\n",
    "\n",
    "scoring = {\"Accuracy\": metrics.make_scorer(metrics.accuracy_score)}\n",
    "\n",
    "#will contain the cv results\n",
    "results = []\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# Nested CV with parameter optimization\n",
    "for train_index, test_index in outer_cv.split(X,y):\n",
    "    X_train,X_test= X.iloc[train_index,:], X.iloc[test_index,:] \n",
    "    y_train,y_test= y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "    grid = GridSearchCV(GaussianNB(),return_train_score=True,scoring=\"accuracy\", refit=True, param_grid=p_grid, n_jobs=-1, cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=1), verbose=3)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    #print(\"Best cross validation accuracy: {:.12f}\".format(grid.best_score_))\n",
    "    #print(\"Test set score: {:.12f}\".format(grid.score(X_test,y_test)))\n",
    "    #print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "    #best_params.append(grid.best_params_)\n",
    "    \n",
    "    #Mas parametros a conseguir\n",
    "    \n",
    "    #y_pred=grid.predict(X_test)\n",
    "    #accuracy.append(metrics.accuracy_score(y_test,y_pred))\n",
    "    #precision.append(metrics.precision_score(y_test,y_pred))\n",
    "    #recall.append(metrics.recall_score(y_test,y_pred))\n",
    "    #f1_score.append(metrics.f1_score(y_test,y_pred))\n",
    "    #confusion_matrix.append(metrics.confusion_matrix(y_test,y_pred))\n",
    "    #parametros=grid.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ba8a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid.cv_results_).to_csv(r\"C:\\Users\\White\\Desktop\\tfg\\generados\\GaussianGridSearchCV.csv\", index = None, header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b692e6",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "315bd770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "X = df.copy()\n",
    "X[\"LabelA\"]=df2[\"LabelA\"]\n",
    "y = X.pop(\"LabelA\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=42)\n",
    "\n",
    "\n",
    "# define the model with default hyperparameters\n",
    "model=RandomForestClassifier(random_state=42)\n",
    "\n",
    "# define the grid of values to search\n",
    "p_grid = { \n",
    "    'n_estimators': [100, 200],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth' : [4,5],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# Nested CV with parameter optimization\n",
    "for train_index, test_index in outer_cv.split(X,y):\n",
    "    X_train,X_test= X.iloc[train_index,:], X.iloc[test_index,:] \n",
    "    y_train,y_test= y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "    grid = GridSearchCV(model,return_train_score=True,scoring=\"accuracy\",param_grid=p_grid, n_jobs=-1, cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=1), verbose=4)\n",
    "    grid.fit(X_train, y_train)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0caeff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid.cv_results_).to_csv(r\"C:\\Users\\White\\Desktop\\tfg\\generados\\RForestGridSearchCV.csv\", index = None, header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60925434",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0b040d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "X = df.copy()\n",
    "X[\"LabelA\"]=df2[\"LabelA\"]\n",
    "y = X.pop(\"LabelA\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=42)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# define the model with default hyperparameters\n",
    "model = AdaBoostClassifier()\n",
    "# define the grid of values to search\n",
    "p_grid = dict()\n",
    "p_grid['n_estimators'] = [10,50,100]\n",
    "p_grid['learning_rate'] = [0.1,0.001,0.0001]\n",
    "scoring = {\"AUC\": \"roc_auc\", \"Accuracy\": metrics.make_scorer(metrics.accuracy_score), \"Precision\":metrics.make_scorer(metrics.precision_score)}\n",
    "\n",
    "#will contain the cv results\n",
    "results = []\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# Nested CV with parameter optimization\n",
    "for train_index, test_index in outer_cv.split(X,y):\n",
    "    X_train,X_test= X.iloc[train_index,:], X.iloc[test_index,:] \n",
    "    y_train,y_test= y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "    grid = GridSearchCV(model,return_train_score=True,scoring=\"accuracy\",param_grid=p_grid, n_jobs=-1, cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=1), verbose=4)\n",
    "    grid.fit(X_train, y_train)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17231836",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid.cv_results_).to_csv(r\"C:\\Users\\White\\Desktop\\tfg\\generados\\AdaboostGridSearchCV.csv\", index = None, header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9266a08",
   "metadata": {},
   "source": [
    "# LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70877f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "X = df.copy()\n",
    "X[\"LabelA\"]=df2[\"LabelA\"]\n",
    "y = X.pop(\"LabelA\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=42)\n",
    "\n",
    "# define the model with default hyperparameters\n",
    "model = LinearSVC()\n",
    "# define the grid of values to search\n",
    "p_grid = {'C':[0.1,10,100]}\n",
    "\n",
    "#will contain the cv results\n",
    "results = []\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# Nested CV with parameter optimization\n",
    "for train_index, test_index in outer_cv.split(X,y):\n",
    "    X_train,X_test= X.iloc[train_index,:], X.iloc[test_index,:] \n",
    "    y_train,y_test= y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "    grid = GridSearchCV(model,return_train_score=True,scoring=\"accuracy\",param_grid=p_grid, n_jobs=2, cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=1), verbose=4)\n",
    "    grid.fit(X_train, y_train)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "811bb930",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid.cv_results_).to_csv(r\"C:\\Users\\White\\Desktop\\tfg\\generados\\LinearSVCGridSearchCV.csv\", index = None, header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8279a7",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afcc46bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/30\n",
      "2676/2676 [==============================] - 3s 924us/step - loss: 0.0113 - accuracy: 0.9976\n",
      "Epoch 2/30\n",
      "2676/2676 [==============================] - 2s 904us/step - loss: 5.6343e-04 - accuracy: 0.9999\n",
      "Epoch 3/30\n",
      "2676/2676 [==============================] - 2s 912us/step - loss: 1.7208e-04 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "2676/2676 [==============================] - 2s 921us/step - loss: 7.6665e-05 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "2676/2676 [==============================] - 2s 907us/step - loss: 4.7982e-05 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "2676/2676 [==============================] - 2s 911us/step - loss: 1.7307e-04 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "2676/2676 [==============================] - 2s 910us/step - loss: 7.7995e-05 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "2676/2676 [==============================] - 2s 918us/step - loss: 3.5254e-06 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "2676/2676 [==============================] - 2s 906us/step - loss: 1.4324e-06 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "2676/2676 [==============================] - 2s 913us/step - loss: 5.1879e-05 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "2676/2676 [==============================] - 2s 907us/step - loss: 1.4337e-05 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "2676/2676 [==============================] - 2s 923us/step - loss: 2.0836e-06 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "2676/2676 [==============================] - 2s 924us/step - loss: 4.0890e-05 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "2676/2676 [==============================] - 2s 910us/step - loss: 5.5823e-05 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "2676/2676 [==============================] - 2s 915us/step - loss: 5.2453e-07 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "2676/2676 [==============================] - 2s 919us/step - loss: 1.1435e-07 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "2676/2676 [==============================] - 2s 907us/step - loss: 6.3778e-08 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "2676/2676 [==============================] - 2s 923us/step - loss: 4.4204e-08 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "2676/2676 [==============================] - 2s 920us/step - loss: 1.8735e-08 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "2676/2676 [==============================] - 2s 913us/step - loss: 1.0789e-08 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "2676/2676 [==============================] - 2s 914us/step - loss: 4.5205e-09 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "2676/2676 [==============================] - 2s 913us/step - loss: 2.6717e-09 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "2676/2676 [==============================] - 3s 948us/step - loss: 1.8213e-09 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "2676/2676 [==============================] - 2s 924us/step - loss: 1.2882e-09 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "2676/2676 [==============================] - 2s 915us/step - loss: 1.0450e-09 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "2676/2676 [==============================] - 2s 910us/step - loss: 8.5699e-10 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "2676/2676 [==============================] - 2s 916us/step - loss: 7.3173e-10 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "2676/2676 [==============================] - 2s 913us/step - loss: 6.3669e-10 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "2676/2676 [==============================] - 2s 919us/step - loss: 5.7818e-10 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "2676/2676 [==============================] - 3s 959us/step - loss: 5.2587e-10 - accuracy: 1.0000\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/10\n",
      "1338/1338 [==============================] - 2s 1ms/step - loss: 0.0201 - accuracy: 0.9969\n",
      "Epoch 2/10\n",
      "1338/1338 [==============================] - 1s 999us/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 3/10\n",
      "1338/1338 [==============================] - 1s 994us/step - loss: 4.6427e-04 - accuracy: 0.9999\n",
      "Epoch 4/10\n",
      "1338/1338 [==============================] - 1s 990us/step - loss: 3.0635e-04 - accuracy: 0.9999\n",
      "Epoch 5/10\n",
      "1338/1338 [==============================] - 1s 1ms/step - loss: 1.1375e-04 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1338/1338 [==============================] - 1s 1ms/step - loss: 1.5900e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1338/1338 [==============================] - 1s 1ms/step - loss: 3.2248e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1338/1338 [==============================] - 1s 1ms/step - loss: 1.2279e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1338/1338 [==============================] - 2s 2ms/step - loss: 6.1032e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1338/1338 [==============================] - 3s 2ms/step - loss: 1.2346e-05 - accuracy: 1.0000\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 0.0130 - accuracy: 0.9972\n",
      "Epoch 2/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 5.6722e-04 - accuracy: 0.9999\n",
      "Epoch 3/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 1.8073e-04 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 9.9950e-05 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 3.7815e-05 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 4.4280e-05 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 1.3540e-04 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 2.0225e-06 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 1.2281e-06 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 3.1062e-05 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 1.0547e-04 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 3.6028e-05 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 1.4841e-06 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 1.6100e-07 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 8.9053e-08 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 5.0906e-08 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 2.7693e-08 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 1.2840e-08 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 8.2810e-09 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 3.2411e-09 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 1.9670e-09 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "2676/2676 [==============================] - 3s 1ms/step - loss: 6.6129e-07 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "2676/2676 [==============================] - 3s 978us/step - loss: 1.5002e-09 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "2676/2676 [==============================] - 3s 965us/step - loss: 1.1747e-09 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "2676/2676 [==============================] - 3s 952us/step - loss: 9.9977e-10 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "2676/2676 [==============================] - 3s 945us/step - loss: 8.7423e-10 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "2676/2676 [==============================] - 3s 969us/step - loss: 7.7524e-10 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "2676/2676 [==============================] - 3s 947us/step - loss: 6.9186e-10 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "2676/2676 [==============================] - 2s 924us/step - loss: 6.3491e-10 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "2676/2676 [==============================] - 2s 916us/step - loss: 5.7680e-10 - accuracy: 1.0000\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/10\n",
      "2676/2676 [==============================] - 3s 926us/step - loss: 0.0125 - accuracy: 0.9982\n",
      "Epoch 2/10\n",
      "2676/2676 [==============================] - 2s 923us/step - loss: 8.0249e-04 - accuracy: 0.9999\n",
      "Epoch 3/10\n",
      "2676/2676 [==============================] - 2s 919us/step - loss: 2.9819e-04 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "2676/2676 [==============================] - 3s 969us/step - loss: 1.8353e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "2676/2676 [==============================] - 2s 910us/step - loss: 7.9866e-05 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "2676/2676 [==============================] - 2s 904us/step - loss: 1.0037e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "2676/2676 [==============================] - 2s 903us/step - loss: 8.3061e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "2676/2676 [==============================] - 2s 910us/step - loss: 7.4729e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "2676/2676 [==============================] - 2s 903us/step - loss: 4.9428e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2676/2676 [==============================] - 2s 902us/step - loss: 9.3234e-07 - accuracy: 1.0000\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Epoch 1/30\n",
      "1338/1338 [==============================] - 2s 991us/step - loss: 0.0165 - accuracy: 0.9975\n",
      "Epoch 2/30\n",
      "1338/1338 [==============================] - 1s 991us/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 3/30\n",
      "1338/1338 [==============================] - 1s 992us/step - loss: 4.6633e-04 - accuracy: 0.9999\n",
      "Epoch 4/30\n",
      "1338/1338 [==============================] - 1s 983us/step - loss: 2.8114e-04 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1338/1338 [==============================] - 1s 981us/step - loss: 2.3213e-04 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1338/1338 [==============================] - 1s 990us/step - loss: 1.9891e-04 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1338/1338 [==============================] - 1s 997us/step - loss: 3.1726e-05 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1338/1338 [==============================] - 1s 993us/step - loss: 1.6998e-05 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1338/1338 [==============================] - 1s 981us/step - loss: 8.4480e-05 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1338/1338 [==============================] - 1s 982us/step - loss: 3.8057e-05 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1338/1338 [==============================] - 1s 982us/step - loss: 4.0137e-06 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1338/1338 [==============================] - 1s 980us/step - loss: 2.7595e-06 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1338/1338 [==============================] - 1s 980us/step - loss: 1.3787e-04 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1338/1338 [==============================] - 1s 981us/step - loss: 2.3002e-04 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1338/1338 [==============================] - 1s 979us/step - loss: 1.1335e-05 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1338/1338 [==============================] - 1s 981us/step - loss: 1.1599e-06 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1338/1338 [==============================] - 1s 988us/step - loss: 7.5521e-07 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1338/1338 [==============================] - 1s 977us/step - loss: 5.2283e-07 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1338/1338 [==============================] - 1s 978us/step - loss: 3.2949e-07 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1338/1338 [==============================] - 1s 981us/step - loss: 2.7431e-07 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1338/1338 [==============================] - 1s 984us/step - loss: 1.3776e-07 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1338/1338 [==============================] - 1s 983us/step - loss: 8.4564e-08 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1338/1338 [==============================] - 1s 976us/step - loss: 5.0013e-08 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1338/1338 [==============================] - 1s 990us/step - loss: 6.4821e-08 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1338/1338 [==============================] - 1s 977us/step - loss: 3.0965e-05 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1338/1338 [==============================] - 1s 975us/step - loss: 9.5489e-06 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1338/1338 [==============================] - 1s 987us/step - loss: 1.6394e-07 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1338/1338 [==============================] - 1s 984us/step - loss: 9.8691e-08 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1338/1338 [==============================] - 1s 975us/step - loss: 6.2898e-08 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1338/1338 [==============================] - 1s 975us/step - loss: 4.3162e-08 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "\n",
    "X = df.copy()\n",
    "X[\"LabelA\"]=df2[\"LabelA\"]\n",
    "y = X.pop(\"LabelA\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=42)\n",
    "\n",
    "#Autoencoder\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    #Enc Dimension \n",
    "    encoding_dim=100\n",
    "    #Input shape\n",
    "    input_dim = Input(shape=(31,))\n",
    "    #Encoding Layer\n",
    "    encoded = Dense(encoding_dim, activation='relu')(input_dim)\n",
    "    #Decoding Layer\n",
    "    decoded = Dense(1, activation='sigmoid')(encoded)\n",
    "\n",
    "    #Model AE\n",
    "    autoencoder = Model(input_dim, decoded)\n",
    "    #Model Encoder \n",
    "    encoder = Model(input_dim, encoded)\n",
    "    #Encoding\n",
    "    encoded_input = Input(shape=(encoding_dim,))\n",
    "    #Decoding \n",
    "    decoder_layer = autoencoder.layers[-1]\n",
    "    #Model Decoder \n",
    "    decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "    #optimizer=tf.keras.optimizers.Adadelta(lr=0.1, rho=0.95, epsilon=None, decay=0.0)\n",
    "    autoencoder.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model = autoencoder\n",
    "\n",
    "    # Compile model\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model)\n",
    "\n",
    "\n",
    "\n",
    "# define the grid search parameters\n",
    "#batch_size = [10, 20, 40]\n",
    "#epochs = [10, 30]\n",
    "#p_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "#batch_size = [10,128]\n",
    "#epochs = [10,50]\n",
    "\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [100, 200]\n",
    "#optimizer= [\"RMSprop\", \"adam\"]\n",
    "epochs = [10, 30]\n",
    "#dropout = [0, 0.1, 0.2]\n",
    "p_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "p_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# Nested CV with parameter optimization\n",
    "for train_index, test_index in outer_cv.split(X,y):\n",
    "    X_train,X_test= X.iloc[train_index,:], X.iloc[test_index,:] \n",
    "    y_train,y_test= y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "    grid = GridSearchCV(model,return_train_score=True,scoring=\"accuracy\",param_grid=p_grid, n_jobs=-1, cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=1), verbose=4)\n",
    "    grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10cb0872",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid.cv_results_).to_csv(r\"C:\\Users\\White\\Desktop\\tfg\\generados\\AutoencoderGridSearchCV.csv\", index = None, header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733076a2",
   "metadata": {},
   "source": [
    "# TensorBoard tryout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39c672d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "--- Starting trial: run-0\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "8360/8360 [==============================] - 10s 1ms/step - loss: 0.0336 - accuracy: 0.9947\n",
      "2090/2090 [==============================] - 2s 719us/step - loss: 0.0011 - accuracy: 0.9998\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "8360/8360 [==============================] - 9s 1ms/step - loss: 0.0574 - accuracy: 0.9898\n",
      "2090/2090 [==============================] - 2s 710us/step - loss: 0.0078 - accuracy: 0.9981\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "8360/8360 [==============================] - 10s 1ms/step - loss: 0.0409 - accuracy: 0.9923\n",
      "2090/2090 [==============================] - 2s 726us/step - loss: 0.0013 - accuracy: 0.9991\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "8360/8360 [==============================] - 10s 1ms/step - loss: 0.0656 - accuracy: 0.9884\n",
      "2090/2090 [==============================] - 2s 728us/step - loss: 0.0077 - accuracy: 0.9980\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "8360/8360 [==============================] - 10s 1ms/step - loss: 0.0208 - accuracy: 0.9964\n",
      "2090/2090 [==============================] - 2s 723us/step - loss: 5.9942e-04 - accuracy: 0.9998\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "8360/8360 [==============================] - 10s 1ms/step - loss: 0.0451 - accuracy: 0.9924\n",
      "2090/2090 [==============================] - 2s 715us/step - loss: 0.0079 - accuracy: 0.9979\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 32, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "8360/8360 [==============================] - 10s 1ms/step - loss: 0.0270 - accuracy: 0.9949\n",
      "2090/2090 [==============================] - 2s 735us/step - loss: 6.9810e-04 - accuracy: 0.9998\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 32, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "8360/8360 [==============================] - 10s 1ms/step - loss: 0.0430 - accuracy: 0.9930\n",
      "2090/2090 [==============================] - 2s 713us/step - loss: 0.0078 - accuracy: 0.9978\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "  )\n",
    "\n",
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    accuracy = train_test_model(hparams)\n",
    "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    "def train_test_model(hparams):\n",
    "  model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax),\n",
    "  ])\n",
    "  model.compile(\n",
    "      optimizer=hparams[HP_OPTIMIZER],\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['accuracy'],\n",
    "  )\n",
    "\n",
    "  model.fit(X_train, y_train, epochs=1) # Run with 1 epoch to speed things up for demo purposes\n",
    "  _, accuracy = model.evaluate(X_test, y_test)\n",
    "  return accuracy\n",
    "\n",
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "      hparams = {\n",
    "          HP_NUM_UNITS: num_units,\n",
    "          HP_DROPOUT: dropout_rate,\n",
    "          HP_OPTIMIZER: optimizer,\n",
    "      }\n",
    "      run_name = \"run-%d\" % session_num\n",
    "      print('--- Starting trial: %s' % run_name)\n",
    "      print({h.name: hparams[h] for h in hparams})\n",
    "      run('logs/hparam_tuning/' + run_name, hparams)\n",
    "      session_num += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dd29866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-faa0334a79e2179f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-faa0334a79e2179f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36231934",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6796f3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 332\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Epoch 1/10\n",
      "1338/1338 [==============================] - 44s 30ms/step - loss: 0.7420 - accuracy: 0.6656\n",
      "Epoch 2/10\n",
      "1338/1338 [==============================] - 41s 31ms/step - loss: 0.4967 - accuracy: 0.7942\n",
      "Epoch 3/10\n",
      "1338/1338 [==============================] - 41s 31ms/step - loss: 0.4809 - accuracy: 0.8130\n",
      "Epoch 4/10\n",
      "1338/1338 [==============================] - 41s 30ms/step - loss: 0.4764 - accuracy: 0.8185\n",
      "Epoch 5/10\n",
      "1338/1338 [==============================] - 41s 30ms/step - loss: 0.4748 - accuracy: 0.8185\n",
      "Epoch 6/10\n",
      "1338/1338 [==============================] - 41s 31ms/step - loss: 0.4745 - accuracy: 0.8185\n",
      "Epoch 7/10\n",
      "1338/1338 [==============================] - 41s 31ms/step - loss: 0.4743 - accuracy: 0.8185\n",
      "Epoch 8/10\n",
      "1338/1338 [==============================] - 41s 31ms/step - loss: 0.4742 - accuracy: 0.8185\n",
      "Epoch 9/10\n",
      "1338/1338 [==============================] - 41s 31ms/step - loss: 0.4743 - accuracy: 0.8185\n",
      "Epoch 10/10\n",
      "1338/1338 [==============================] - 41s 31ms/step - loss: 0.4741 - accuracy: 0.8185\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Epoch 1/10\n",
      "1338/1338 [==============================] - 45s 31ms/step - loss: 0.6461 - accuracy: 0.7144\n",
      "Epoch 2/10\n",
      "1338/1338 [==============================] - 41s 31ms/step - loss: 0.4866 - accuracy: 0.8038\n",
      "Epoch 3/10\n",
      "1338/1338 [==============================] - 42s 31ms/step - loss: 0.4759 - accuracy: 0.8185\n",
      "Epoch 4/10\n",
      "1338/1338 [==============================] - 42s 31ms/step - loss: 0.4742 - accuracy: 0.8185\n",
      "Epoch 5/10\n",
      "1338/1338 [==============================] - 42s 31ms/step - loss: 0.4742 - accuracy: 0.8185\n",
      "Epoch 6/10\n",
      "1338/1338 [==============================] - 42s 31ms/step - loss: 0.4742 - accuracy: 0.8185\n",
      "Epoch 7/10\n",
      "1338/1338 [==============================] - 42s 31ms/step - loss: 0.4742 - accuracy: 0.8185\n",
      "Epoch 8/10\n",
      "1338/1338 [==============================] - 42s 31ms/step - loss: 0.4741 - accuracy: 0.8185\n",
      "Epoch 9/10\n",
      "1338/1338 [==============================] - 42s 31ms/step - loss: 0.4741 - accuracy: 0.8185\n",
      "Epoch 10/10\n",
      "1338/1338 [==============================] - 42s 31ms/step - loss: 0.4741 - accuracy: 0.8185\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Epoch 1/10\n",
      "1338/1338 [==============================] - 43s 30ms/step - loss: 0.6691 - accuracy: 0.6999\n",
      "Epoch 2/10\n",
      "1338/1338 [==============================] - 42s 31ms/step - loss: 0.4917 - accuracy: 0.7971\n",
      "Epoch 3/10\n",
      "1338/1338 [==============================] - 42s 32ms/step - loss: 0.4806 - accuracy: 0.8131\n",
      "Epoch 4/10\n",
      "1338/1338 [==============================] - 42s 32ms/step - loss: 0.4761 - accuracy: 0.8185\n",
      "Epoch 5/10\n",
      "1338/1338 [==============================] - 42s 31ms/step - loss: 0.4745 - accuracy: 0.8185\n",
      "Epoch 6/10\n",
      "1338/1338 [==============================] - 42s 31ms/step - loss: 0.4742 - accuracy: 0.8185\n",
      "Epoch 7/10\n",
      "1338/1338 [==============================] - 42s 31ms/step - loss: 0.4742 - accuracy: 0.8185\n",
      "Epoch 8/10\n",
      "1338/1338 [==============================] - 42s 31ms/step - loss: 0.4741 - accuracy: 0.8185\n",
      "Epoch 9/10\n",
      "1338/1338 [==============================] - 42s 31ms/step - loss: 0.4741 - accuracy: 0.8185\n",
      "Epoch 10/10\n",
      "1338/1338 [==============================] - 42s 31ms/step - loss: 0.4741 - accuracy: 0.8185\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Epoch 1/10\n",
      "1338/1338 [==============================] - 45s 32ms/step - loss: 0.6541 - accuracy: 0.7156\n",
      "Epoch 2/10\n",
      "1338/1338 [==============================] - 42s 32ms/step - loss: 0.4895 - accuracy: 0.7989\n",
      "Epoch 3/10\n",
      "1338/1338 [==============================] - 42s 32ms/step - loss: 0.4790 - accuracy: 0.8175\n",
      "Epoch 4/10\n",
      "1338/1338 [==============================] - 42s 32ms/step - loss: 0.4749 - accuracy: 0.8185\n",
      "Epoch 5/10\n",
      "1338/1338 [==============================] - 42s 32ms/step - loss: 0.4743 - accuracy: 0.8185\n",
      "Epoch 6/10\n",
      "1338/1338 [==============================] - 42s 32ms/step - loss: 0.4744 - accuracy: 0.8185\n",
      "Epoch 7/10\n",
      "1338/1338 [==============================] - 42s 32ms/step - loss: 0.4742 - accuracy: 0.8185\n",
      "Epoch 8/10\n",
      "1338/1338 [==============================] - 42s 32ms/step - loss: 0.4742 - accuracy: 0.8185\n",
      "Epoch 9/10\n",
      "1338/1338 [==============================] - 42s 32ms/step - loss: 0.4743 - accuracy: 0.8185\n",
      "Epoch 10/10\n",
      "1338/1338 [==============================] - 42s 32ms/step - loss: 0.4742 - accuracy: 0.8185\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Epoch 1/10\n",
      "1338/1338 [==============================] - 44s 31ms/step - loss: 0.6758 - accuracy: 0.7036\n",
      "Epoch 2/10\n",
      "1338/1338 [==============================] - 41s 31ms/step - loss: 0.4936 - accuracy: 0.7968\n",
      "Epoch 3/10\n",
      "1338/1338 [==============================] - 41s 31ms/step - loss: 0.4786 - accuracy: 0.8158\n",
      "Epoch 4/10\n",
      "1338/1338 [==============================] - 41s 31ms/step - loss: 0.4745 - accuracy: 0.8185\n",
      "Epoch 5/10\n",
      "1338/1338 [==============================] - 41s 31ms/step - loss: 0.4742 - accuracy: 0.8185\n",
      "Epoch 6/10\n",
      "1338/1338 [==============================] - 41s 31ms/step - loss: 0.4744 - accuracy: 0.8185\n",
      "Epoch 7/10\n",
      "1338/1338 [==============================] - 41s 31ms/step - loss: 0.4741 - accuracy: 0.8185\n",
      "Epoch 8/10\n",
      "1338/1338 [==============================] - 41s 31ms/step - loss: 0.4741 - accuracy: 0.8185\n",
      "Epoch 9/10\n",
      "1338/1338 [==============================] - 41s 31ms/step - loss: 0.4741 - accuracy: 0.8185\n",
      "Epoch 10/10\n",
      "1338/1338 [==============================] - 41s 31ms/step - loss: 0.4741 - accuracy: 0.8185\n"
     ]
    }
   ],
   "source": [
    "# Part 2 - Building the RNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "X = df.copy()\n",
    "X[\"LabelA\"]=df2[\"LabelA\"]\n",
    "y = X.pop(\"LabelA\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=42)\n",
    "\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "# Initialising the RNN\n",
    "def create_model():\n",
    "    #Initializing the RNN\n",
    "    model = Sequential()\n",
    "    #Adding the first LSTM layer and dropout regularization\n",
    "    model.add(LSTM(units=20, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(Dropout(0))\n",
    "    #Adding the second LSTM layer and dropout regularization\n",
    "    model.add(LSTM(units=20, return_sequences=True))\n",
    "    model.add(Dropout(0))\n",
    "    #Adding the output layer\n",
    "    model.add(Dense(units=1))\n",
    "    #Compiling the model without training\n",
    "    model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [200]\n",
    "#optimizer= [\"RMSprop\", \"adam\"]\n",
    "epochs = [10, 20]\n",
    "#dropout = [0, 0.1, 0.2]\n",
    "p_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# Nested CV with parameter optimization\n",
    "for train_index, test_index in outer_cv.split(X,y):\n",
    "    X_train,X_test= X.iloc[train_index,:], X.iloc[test_index,:] \n",
    "    y_train,y_test= y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "    grid = GridSearchCV(model,return_train_score=True,scoring=\"accuracy\",param_grid=p_grid, n_jobs=-1, cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=1), verbose=4)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a0d00ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid.cv_results_).to_csv(r\"C:\\Users\\White\\Desktop\\tfg\\generados\\RNNGridSearchCV.csv\", index = None, header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38467c5",
   "metadata": {},
   "source": [
    "# Building the CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ded87288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8052/2802444900.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                 \u001b[1;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n"
     ]
    }
   ],
   "source": [
    "#Building the CNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "X = df.copy()\n",
    "X[\"LabelA\"]=df2[\"LabelA\"]\n",
    "y = X.pop(\"LabelA\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=42)\n",
    "\n",
    "nX_train=X_train.to_numpy()\n",
    "nX_train = nX_train[..., np.newaxis]\n",
    "nX_test=X_test.to_numpy()\n",
    "nX_test = nX_test[..., np.newaxis]\n",
    "\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "# Initialising the CNN\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(nX_train.shape[1],nX_train.shape[2] )))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model)\n",
    "\n",
    "\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [32, 64]\n",
    "#optimizer= [\"RMSprop\", \"adam\"]\n",
    "epochs = [10, 20]\n",
    "#dropout = [0, 0.1, 0.2]\n",
    "p_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# Nested CV with parameter optimization\n",
    "for train_index, test_index in outer_cv.split(X,y):\n",
    "    X_train,X_test= X.iloc[train_index,:], X.iloc[test_index,:] \n",
    "    y_train,y_test= y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "    grid = GridSearchCV(model,return_train_score=True,scoring=\"accuracy\",param_grid=p_grid, n_jobs=-1, cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=1), verbose=4)\n",
    "    grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8396a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid.cv_results_).to_csv(r\"C:\\Users\\White\\Desktop\\tfg\\generados\\CNNGridSearchCV.csv\", index = None, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b448557",
   "metadata": {},
   "outputs": [],
   "source": [
    "nX_train=X_train.to_numpy()\n",
    "nX_train = nX_train[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22365dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c441b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-9.13798267e-01],\n",
       "        [ 2.06517507e+00],\n",
       "        [-6.23681245e-02],\n",
       "        ...,\n",
       "        [-1.60936040e+00],\n",
       "        [-6.42964049e-01],\n",
       "        [ 2.12768266e+00]],\n",
       "\n",
       "       [[ 1.74578570e+00],\n",
       "        [-4.03402134e-01],\n",
       "        [-6.23681245e-02],\n",
       "        ...,\n",
       "        [ 6.21364859e-01],\n",
       "        [-6.42964049e-01],\n",
       "        [-4.69994900e-01]],\n",
       "\n",
       "       [[ 1.46934696e+00],\n",
       "        [-4.92854044e-01],\n",
       "        [ 6.85065613e-04],\n",
       "        ...,\n",
       "        [ 6.21364859e-01],\n",
       "        [-6.42964049e-01],\n",
       "        [-4.69994900e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-9.13798267e-01],\n",
       "        [ 2.10691519e+00],\n",
       "        [-6.23681245e-02],\n",
       "        ...,\n",
       "        [-1.60936040e+00],\n",
       "        [-6.42964049e-01],\n",
       "        [ 2.12768266e+00]],\n",
       "\n",
       "       [[ 1.04284389e+00],\n",
       "        [ 1.56518800e-01],\n",
       "        [-6.23681245e-02],\n",
       "        ...,\n",
       "        [ 6.21364859e-01],\n",
       "        [-6.42964049e-01],\n",
       "        [-4.69994900e-01]],\n",
       "\n",
       "       [[ 8.18404276e-01],\n",
       "        [-4.92854044e-01],\n",
       "        [ 6.85065613e-04],\n",
       "        ...,\n",
       "        [ 6.21364859e-01],\n",
       "        [-6.42964049e-01],\n",
       "        [-4.69994900e-01]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nX_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3559e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
